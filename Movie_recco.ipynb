{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29292154-5ae2-44ff-bc9a-efde1129d7fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "511aa4fe-57b2-4cd0-9fcb-172363fac60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv('/Users/vishnuadithya/Downloads/indian movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffda4a3-935f-4d26-b632-cea02e0b6dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie['Language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d609c-e7a2-460f-81e0-87d9fcc2b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343d8cf-b6c4-4175-9a33-40952862bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01800b9-1424-4b68-97f6-f8776ad5e712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debea684-5bab-4205-960b-d22df8ca6a74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9457e5ec-55ac-4bc5-86fb-1250bba20f60",
   "metadata": {},
   "source": [
    "# splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b76d995-6353-4fe1-99d4-b54c89006888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie['Genre'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "321278a3-76f3-4576-847e-0718311ba249",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie['Genre'] = movie['Genre'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "77cbbac1-7396-47cb-9810-06a79c37598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_list = sorted(set(genre.strip() for genres in movie['Genre'] for genre in genres))\n",
    "# for genre in genres_list:\n",
    "#     movies_df[genre] = movies['genres'].apply(lambda x: int(genre in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "69044669-dc64-4623-bc85-1f79d2171258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for genres in genres_list:  \n",
    "     for genre in genres:\n",
    "          genre=genre.strip();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae71cc-2a9e-4f4f-9e1b-37066be02c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_list.pop(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3a405b-4483-4984-8a8e-02ffc37d4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7c4f6-ef03-4e9f-9b31-097ac91d78b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9137d4af-e413-4da5-91b7-24eaf42533f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie= movie.drop('Genre',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "254d63e4-d9ff-4dbe-aa64-b2de6ff8f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie['Genre'] = movie['Genre'].apply(lambda x: x.split(',') if isinstance(x, str) else x)\n",
    "\n",
    "# Step 2: Ensure all genres are stripped of any leading or trailing whitespace\n",
    "movie['Genre'] = movie['Genre'].apply(lambda x: [genre.strip() for genre in x])\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Create binary columns for each genre\n",
    "for genre in genres_list:\n",
    "    movie[genre] = movie['Genre'].apply(lambda x: int(genre in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# Features**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_features = movie.drop(columns=['ID', 'Movie Name',  'Genre'])\n",
    "\n",
    "# Convert all columns to numeric and handle non-numeric values\n",
    "movie_features = movie_features.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill missing values with the mean of each column\n",
    "movie_features.fillna(movie_features.mean(), inplace=True)\n",
    "\n",
    "# Check for any remaining NaN values\n",
    "print(\"Number of NaN values after filling with mean:\", movie_features.isna().sum().sum())\n",
    "\n",
    "# Convert any remaining NaN values to zero\n",
    "movie_features.fillna(0, inplace=True)\n",
    "\n",
    "# Check again for NaN values\n",
    "print(\"Number of NaN values after converting remaining to zero:\", movie_features.isna().sum().sum())\n",
    "\n",
    "# # Standardize the features\n",
    "# scaler = StandardScaler()\n",
    "# movie_features_scaled = scaler.fit_transform(movie_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Drop the original genres column\n",
    "# df = df.drop(columns=['Genre'])\n",
    "\n",
    "# Separate the movie names and genre features\n",
    "movie_names = movie['Movie Name']\n",
    "# genre_features = df.drop(columns=['Movie Name','ID'])\n",
    "\n",
    "# Initialize the KNN model\n",
    "knn = NearestNeighbors(n_neighbors=3, metric='euclidean')\n",
    "\n",
    "# Fit the model\n",
    "knn.fit(movie_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find similar movies\n",
    "def recommend_movies(movie_name, k=5):\n",
    "    if movie_name not in movie_names.values:\n",
    "        return \"Movie not found\"\n",
    "    \n",
    "    movie_index = movie_names[movie_names == movie_name].index[0]\n",
    "    movie_vector = movie_features.iloc[movie_index].values.reshape(1, -1)\n",
    "    \n",
    "    distances, indices = knn.kneighbors(movie_vector, n_neighbors=k+1)\n",
    "    similar_movies = movie_names.iloc[indices.flatten()[1:]].values\n",
    "    return similar_movies\n",
    "\n",
    "# Example usage\n",
    "input_movie = 'Theri'\n",
    "print(f\"Movies similar to {input_movie}: {recommend_movies(input_movie, k=5)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the data\n",
    "movie = pd.read_csv('/Users/vishnuadithya/Downloads/indian movies.csv')\n",
    "\n",
    "def preprocess_data(movie):\n",
    "  \n",
    "\n",
    "    # Convert 'Year' to numeric and calculate movie age\n",
    "    current_year = 2024\n",
    "    movie['Year'] = pd.to_numeric(movie['Year'], errors='coerce')\n",
    "    movie['Movie_Age'] = current_year - movie['Year']\n",
    "\n",
    "    # Clean and convert numeric columns\n",
    "    numeric_columns = ['Timing', 'Rating(10)', 'Votes', 'Movie_Age']\n",
    "    for col in numeric_columns:\n",
    "        movie[col] = pd.to_numeric(movie[col].replace(['-', 'unknown'], np.nan), errors='coerce')\n",
    "   \n",
    "    \n",
    "\n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    movie[numeric_columns] = imputer.fit_transform(movie[numeric_columns])\n",
    "\n",
    "    # Normalize numeric columns\n",
    "    scaler = MinMaxScaler()\n",
    "    movie[numeric_columns] = scaler.fit_transform(movie[numeric_columns])\n",
    "\n",
    "    # One-hot encoding for 'Language'\n",
    "    movie['Language'] = movie['Language'].fillna('Unknown')\n",
    "    language_dummies = pd.get_dummies(movie['Language'], prefix='Lang')\n",
    "    \n",
    "\n",
    "    \n",
    "    movie = pd.concat([movie, language_dummies], axis=1)\n",
    "\n",
    "\n",
    "    # Process 'Genre'\n",
    "    movie['Genre'] = movie['Genre'].fillna('')\n",
    "    movie['Genre'] = movie['Genre'].apply(lambda x: [genre.strip() for genre in str(x).split(',')] if pd.notna(x) else [])\n",
    "    genres_list = sorted(set(genre for genres in movie['Genre'] for genre in genres if genre))\n",
    "    for genre in genres_list:\n",
    "        movie[f'Genre_{genre}'] = movie['Genre'].apply(lambda x: int(genre in x))\n",
    "\n",
    "    # Select features for recommendation\n",
    "    feature_columns = numeric_columns + list(language_dummies.columns) + [f'Genre_{genre}' for genre in genres_list]\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Final check for NaN values\n",
    "    movie_features = movie[feature_columns]\n",
    "    if movie_features.isnull().values.any():\n",
    "        print(\"Warning: NaN values still present in the following columns:\")\n",
    "        print(movie_features.columns[movie_features.isnull().any()].tolist())\n",
    "        print(\"Filling remaining NaN values with 0\")\n",
    "        movie_features = movie_features.fillna(0)\n",
    "    \n",
    "\n",
    "    \n",
    "    return movie, feature_columns, movie_features\n",
    "\n",
    "# Preprocess the data\n",
    "movie, feature_columns, movie_features = preprocess_data(movie)\n",
    "\n",
    "# Initialize and fit KNN model\n",
    "knn = NearestNeighbors(n_neighbors=6, metric='euclidean')\n",
    "knn.fit(movie_features)\n",
    "\n",
    "def recommend_movies(movie_name, k=5):\n",
    "    if movie_name not in movie['Movie Name'].values:\n",
    "        return \"Movie not found\"\n",
    "    \n",
    "    movie_index = movie[movie['Movie Name'] == movie_name].index[0]\n",
    "    movie_vector = movie_features.iloc[movie_index].values.reshape(1, -1)\n",
    "    \n",
    "    distances, indices = knn.kneighbors(movie_vector, n_neighbors=k+1)\n",
    "    similar_movies = movie.iloc[indices.flatten()[1:]]['Movie Name'].values\n",
    "    return similar_movies\n",
    "movie.info\n",
    "# Example usage\n",
    "input_movie = 'Gabbar Singh'\n",
    "print(f\"Movies similar to {input_movie}: {recommend_movies(input_movie, k=5)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the data\n",
    "movie = pd.read_csv('/Users/vishnuadithya/Downloads/indian movies.csv')\n",
    "\n",
    "def preprocess_data(movie):\n",
    "    # Strip leading/trailing spaces from string columns\n",
    "    movie['Movie Name'] = movie['Movie Name'].str.strip()\n",
    "    movie['Language'] = movie['Language'].str.strip()\n",
    "\n",
    "    # Convert 'Year' to numeric and calculate movie age\n",
    "    current_year = 2024\n",
    "    movie['Year'] = pd.to_numeric(movie['Year'], errors='coerce')\n",
    "    movie['Movie_Age'] = current_year - movie['Year']\n",
    "\n",
    "    # Clean and convert numeric columns\n",
    "    numeric_columns = ['Timing', 'Rating(10)', 'Votes', 'Movie_Age']\n",
    "    for col in numeric_columns:\n",
    "        movie[col] = pd.to_numeric(movie[col].replace(['-', 'unknown'], np.nan), errors='coerce')\n",
    "   \n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    movie[numeric_columns] = imputer.fit_transform(movie[numeric_columns])\n",
    "\n",
    "    # Normalize numeric columns\n",
    "    scaler = MinMaxScaler()\n",
    "    movie[numeric_columns] = scaler.fit_transform(movie[numeric_columns])\n",
    "\n",
    "    # One-hot encoding for 'Language'\n",
    "    movie['Language'] = movie['Language'].fillna('Unknown')\n",
    "    language_dummies = pd.get_dummies(movie['Language'], prefix='Lang')\n",
    "    movie = pd.concat([movie, language_dummies], axis=1)\n",
    "\n",
    "    # Process 'Genre'\n",
    "    movie['Genre'] = movie['Genre'].fillna('')\n",
    "    movie['Genre'] = movie['Genre'].apply(lambda x: [genre.strip() for genre in str(x).split(',')] if pd.notna(x) else [])\n",
    "    genres_list = sorted(set(genre for genres in movie['Genre'] for genre in genres if genre))\n",
    "    for genre in genres_list:\n",
    "        movie[f'Genre_{genre}'] = movie['Genre'].apply(lambda x: int(genre in x))\n",
    "\n",
    "    # Select features for recommendation\n",
    "    feature_columns = numeric_columns + list(language_dummies.columns) + [f'Genre_{genre}' for genre in genres_list]\n",
    "    \n",
    "    # Final check for NaN values\n",
    "    movie_features = movie[feature_columns]\n",
    "    if movie_features.isnull().values.any():\n",
    "        print(\"Warning: NaN values still present in the following columns:\")\n",
    "        print(movie_features.columns[movie_features.isnull().any()].tolist())\n",
    "        print(\"Filling remaining NaN values with 0\")\n",
    "        movie_features = movie_features.fillna(0)\n",
    "    \n",
    "    return movie, feature_columns, movie_features\n",
    "\n",
    "# Preprocess the data\n",
    "movie, feature_columns, movie_features = preprocess_data(movie)\n",
    "\n",
    "# Initialize and fit KNN model\n",
    "knn = NearestNeighbors(n_neighbors=6, metric='euclidean')\n",
    "knn.fit(movie_features)\n",
    "\n",
    "def recommend_movies(movie_name, movie_language, k=5):\n",
    "    # Strip leading/trailing spaces from input\n",
    "    movie_name = movie_name.strip()\n",
    "    movie_language = movie_language.strip()\n",
    "\n",
    "    # Filter movies by name and language\n",
    "    filtered_movies = movie[(movie['Movie Name'].str.lower() == movie_name.lower()) & \n",
    "                            (movie['Language'].str.lower() == movie_language.lower())]\n",
    "    \n",
    "    if filtered_movies.empty:\n",
    "        return \"Movie not found\"\n",
    "    \n",
    "    movie_index = filtered_movies.index[0]\n",
    "    movie_vector = movie_features.iloc[movie_index].values.reshape(1, -1)\n",
    "    \n",
    "    distances, indices = knn.kneighbors(movie_vector, n_neighbors=k+1)\n",
    "    similar_movies = movie.iloc[indices.flatten()[1:]]['Movie Name'].values\n",
    "    return similar_movies\n",
    "\n",
    "# Example usage\n",
    "input_movie = 'Kaashmora'\n",
    "input_language = 'tamil'\n",
    "print(f\"Movies similar to {input_movie} ({input_language}): {recommend_movies(input_movie, input_language, k=5)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the data\n",
    "movie = pd.read_csv('/Users/vishnuadithya/Downloads/indian movies.csv')\n",
    "\n",
    "def preprocess_data(movie):\n",
    "    # Strip leading/trailing spaces from string columns\n",
    "    movie['Movie Name'] = movie['Movie Name'].str.strip()\n",
    "    movie['Language'] = movie['Language'].str.strip()\n",
    "\n",
    "    # Convert 'Year' to numeric and calculate movie age\n",
    "    current_year = 2024\n",
    "    movie['Year'] = pd.to_numeric(movie['Year'], errors='coerce')\n",
    "    movie['Movie_Age'] = current_year - movie['Year']\n",
    "\n",
    "    # Clean and convert numeric columns\n",
    "    numeric_columns = ['Timing', 'Rating(10)', 'Votes', 'Movie_Age']\n",
    "    for col in numeric_columns:\n",
    "        movie[col] = pd.to_numeric(movie[col].replace(['-', 'unknown'], np.nan), errors='coerce')\n",
    "   \n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    movie[numeric_columns] = imputer.fit_transform(movie[numeric_columns])\n",
    "\n",
    "    # Normalize numeric columns\n",
    "    scaler = MinMaxScaler()\n",
    "    movie[numeric_columns] = scaler.fit_transform(movie[numeric_columns])\n",
    "\n",
    "    # One-hot encoding for 'Language'\n",
    "    movie['Language'] = movie['Language'].fillna('Unknown')\n",
    "    language_dummies = pd.get_dummies(movie['Language'], prefix='Lang')\n",
    "    movie = pd.concat([movie, language_dummies], axis=1)\n",
    "\n",
    "    # Process 'Genre'\n",
    "    movie['Genre'] = movie['Genre'].fillna('')\n",
    "    movie['Genre'] = movie['Genre'].apply(lambda x: [genre.strip() for genre in str(x).split(',')] if pd.notna(x) else [])\n",
    "    genres_list = sorted(set(genre for genres in movie['Genre'] for genre in genres if genre))\n",
    "    for genre in genres_list:\n",
    "        movie[f'Genre_{genre}'] = movie['Genre'].apply(lambda x: int(genre in x))\n",
    "\n",
    "    # Select features for recommendation\n",
    "    feature_columns = numeric_columns + list(language_dummies.columns) + [f'Genre_{genre}' for genre in genres_list]\n",
    "    \n",
    "    # Final check for NaN values\n",
    "    movie_features = movie[feature_columns]\n",
    "    if movie_features.isnull().values.any():\n",
    "        print(\"Warning: NaN values still present in the following columns:\")\n",
    "        print(movie_features.columns[movie_features.isnull().any()].tolist())\n",
    "        print(\"Filling remaining NaN values with 0\")\n",
    "        movie_features = movie_features.fillna(0)\n",
    "    \n",
    "    return movie, feature_columns, movie_features\n",
    "\n",
    "# Preprocess the data\n",
    "movie, feature_columns, movie_features = preprocess_data(movie)\n",
    "\n",
    "# Initialize and fit KNN model\n",
    "knn = NearestNeighbors(n_neighbors=6, metric='euclidean')\n",
    "knn.fit(movie_features)\n",
    "\n",
    "def recommend_movies(movie_name, movie_language, year_gap=None, k=5):\n",
    "    # Strip leading/trailing spaces from input\n",
    "    movie_name = movie_name.strip()\n",
    "    movie_language = movie_language.strip()\n",
    "\n",
    "    # Filter movies by name and language\n",
    "    filtered_movies = movie[(movie['Movie Name'].str.lower() == movie_name.lower()) & \n",
    "                            (movie['Language'].str.lower() == movie_language.lower())]\n",
    "    \n",
    "    if filtered_movies.empty:\n",
    "        return \"Movie not found\"\n",
    "    \n",
    "    movie_index = filtered_movies.index[0]\n",
    "    movie_vector = movie_features.iloc[movie_index].values.reshape(1, -1)\n",
    "    \n",
    "    distances, indices = knn.kneighbors(movie_vector, n_neighbors=k+1)\n",
    "    similar_movies = movie.iloc[indices.flatten()[1:]]\n",
    "\n",
    "    # Apply year gap filter if specified\n",
    "    if year_gap:\n",
    "        movie_year = movie.loc[movie_index, 'Year']\n",
    "        similar_movies = similar_movies[(similar_movies['Year'] >= movie_year - year_gap) & \n",
    "                                        (similar_movies['Year'] <= movie_year + year_gap)]\n",
    "\n",
    "    return similar_movies['Movie Name'].values\n",
    "\n",
    "# Example usage\n",
    "input_movie = 'Eega'\n",
    "input_language = 'Telugu'\n",
    "year_gap = 5  # Optional: specify the year gap\n",
    "print(f\"Movies similar to {input_movie} ({input_language}) with a year gap of {year_gap}: {recommend_movies(input_movie, input_language, year_gap, k=5)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the data\n",
    "movie = pd.read_csv('/Users/vishnuadithya/Downloads/indian movies.csv')\n",
    "\n",
    "def preprocess_data(movie):\n",
    "    # Strip leading/trailing spaces from string columns\n",
    "    movie['Movie Name'] = movie['Movie Name'].str.strip()\n",
    "    movie['Language'] = movie['Language'].str.strip()\n",
    "\n",
    "    # Convert 'Year' to numeric and calculate movie age\n",
    "    current_year = 2024\n",
    "    movie['Year'] = pd.to_numeric(movie['Year'], errors='coerce')\n",
    "    movie['Movie_Age'] = current_year - movie['Year']\n",
    "\n",
    "    # Clean and convert numeric columns\n",
    "    numeric_columns = ['Timing', 'Rating(10)', 'Votes', 'Movie_Age']\n",
    "    for col in numeric_columns:\n",
    "        movie[col] = pd.to_numeric(movie[col].replace(['-', 'unknown'], np.nan), errors='coerce')\n",
    "   \n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    movie[numeric_columns] = imputer.fit_transform(movie[numeric_columns])\n",
    "\n",
    "    # Normalize numeric columns\n",
    "    scaler = MinMaxScaler()\n",
    "    movie[numeric_columns] = scaler.fit_transform(movie[numeric_columns])\n",
    "\n",
    "    # One-hot encoding for 'Language'\n",
    "    movie['Language'] = movie['Language'].fillna('Unknown')\n",
    "    language_dummies = pd.get_dummies(movie['Language'], prefix='Lang')\n",
    "    movie = pd.concat([movie, language_dummies], axis=1)\n",
    "\n",
    "    # Process 'Genre'\n",
    "    movie['Genre'] = movie['Genre'].fillna('')\n",
    "    movie['Genre'] = movie['Genre'].apply(lambda x: [genre.strip() for genre in str(x).split(',')] if pd.notna(x) else [])\n",
    "    genres_list = sorted(set(genre for genres in movie['Genre'] for genre in genres if genre))\n",
    "    for genre in genres_list:\n",
    "        movie[f'Genre_{genre}'] = movie['Genre'].apply(lambda x: int(genre in x))\n",
    "\n",
    "    # Select features for recommendation\n",
    "    feature_columns = numeric_columns + list(language_dummies.columns) + [f'Genre_{genre}' for genre in genres_list]\n",
    "    \n",
    "    # Final check for NaN values\n",
    "    movie_features = movie[feature_columns]\n",
    "    if movie_features.isnull().values.any():\n",
    "        print(\"Warning: NaN values still present in the following columns:\")\n",
    "        print(movie_features.columns[movie_features.isnull().any()].tolist())\n",
    "        print(\"Filling remaining NaN values with 0\")\n",
    "        movie_features = movie_features.fillna(0)\n",
    "    \n",
    "    return movie, feature_columns, movie_features\n",
    "\n",
    "# Preprocess the data\n",
    "movie, feature_columns, movie_features = preprocess_data(movie)\n",
    "\n",
    "# Initialize and fit KNN model\n",
    "knn = NearestNeighbors(n_neighbors=6, metric='euclidean')\n",
    "knn.fit(movie_features)\n",
    "\n",
    "def recommend_movies(movie_df, movie_features, knn_model, movie_name, movie_language, year_gap=None, k=5):\n",
    "    # Strip leading/trailing spaces from input\n",
    "    movie_name = movie_name.strip()\n",
    "    movie_language = movie_language.strip()\n",
    "    \n",
    "    # Filter movies by name and language\n",
    "    filtered_movies = movie_df[(movie_df['Movie Name'].str.lower() == movie_name.lower()) &\n",
    "                               (movie_df['Language'].str.lower() == movie_language.lower())]\n",
    "    \n",
    "    if filtered_movies.empty:\n",
    "        return \"Movie not found\"\n",
    "    \n",
    "    movie_index = filtered_movies.index[0]\n",
    "    movie_vector = movie_features.iloc[movie_index].values.reshape(1, -1)\n",
    "    \n",
    "    if year_gap:\n",
    "        min_gap, max_gap = map(int, year_gap.split('-'))\n",
    "        movie_year = movie_df.loc[movie_index, 'Year']\n",
    "        year_filter = (movie_df['Year'] >= movie_year + min_gap) & (movie_df['Year'] <= movie_year + max_gap)\n",
    "        \n",
    "        # Get more neighbors initially to account for year filtering\n",
    "        n_neighbors = min(len(movie_df) - 1, k * 10)  # Increased multiplier\n",
    "        distances, indices = knn_model.kneighbors(movie_vector, n_neighbors=n_neighbors + 1)\n",
    "        \n",
    "        # Create a DataFrame with distances and apply year filter\n",
    "        similar_movies = pd.DataFrame({\n",
    "            'index': indices.flatten()[1:],\n",
    "            'distance': distances.flatten()[1:]\n",
    "        })\n",
    "        similar_movies = similar_movies[year_filter.iloc[similar_movies['index']].values]\n",
    "        \n",
    "        # If we still don't have enough recommendations, get more neighbors\n",
    "        while len(similar_movies) < k and n_neighbors < len(movie_df) - 1:\n",
    "            n_neighbors = min(len(movie_df) - 1, n_neighbors * 2)\n",
    "            distances, indices = knn_model.kneighbors(movie_vector, n_neighbors=n_neighbors + 1)\n",
    "            new_similar = pd.DataFrame({\n",
    "                'index': indices.flatten()[1:],\n",
    "                'distance': distances.flatten()[1:]\n",
    "            })\n",
    "            new_similar = new_similar[year_filter.iloc[new_similar['index']].values]\n",
    "            similar_movies = pd.concat([similar_movies, new_similar]).drop_duplicates(subset='index')\n",
    "        \n",
    "        # Sort by distance and select top k\n",
    "        similar_movies = similar_movies.sort_values('distance').head(k)\n",
    "        recommended_indices = similar_movies['index'].values\n",
    "    else:\n",
    "        # If no year gap, just get k neighbors\n",
    "        distances, indices = knn_model.kneighbors(movie_vector, n_neighbors=k+1)\n",
    "        recommended_indices = indices.flatten()[1:]\n",
    "    \n",
    "    return movie_df.loc[recommended_indices, 'Movie Name'].values\n",
    "\n",
    "# Example usage\n",
    "input_movie = 'maanagaram'\n",
    "input_language = 'Tamil'\n",
    "year_gap = '1-20'  # Optional: specify the year gap\n",
    "\n",
    "recommendations = recommend_movies(movie, movie_features, knn, input_movie, input_language, year_gap, k=5)\n",
    "print(f\"Movies similar to {input_movie} ({input_language}) with a year gap of {year_gap}:\")\n",
    "for i, rec_movie in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {rec_movie}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
